---
title: "FitBit"
author: "Michaela Jírù"
date: "15 èervna 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("C:/Users/test/Documents/Data science/Machine Learning")
library("caret")
library("ggplot2")
knitr::opts_chunk$set(cache=TRUE)
```

## Fitbit prediction

This paper is an assigment from the Coursera course Practical Machine Learning, a part of Data Science Specialization. The goal is to predict the manner of fitbit's users the practised and excercise based on the data from  accelerometers on the belt, forearm, arm, and dumbell of 6 participants.

##Prepartion
Firstly, I am going to load in the traing and the testing data and see the dimensions.
```{r load}
train <- read.csv("pml-training.csv",na.strings=c("NA",""))
test <- read.csv("pml-testing.csv",na.strings=c("NA",""))
#head(train)
dim(train)

```
There is a lot of variables, wee need to remove those with a lot of NAs those which seem to be irrelevant.
```{r clean}
isNA <- apply(train, 2, function(x) { sum(is.na(x)) })
notNa <- subset(train[, which(isNA == 0)], )
finalTrain <- notNa[,-(1:7)]
dim(finalTrain)

```
That leaves us with 53 variables. Let's split it into training and testing dataset.
```{r split}
inTrain <- createDataPartition(finalTrain$classe, p=0.7, list=F)
training <- finalTrain[inTrain,]
testing <- finalTrain[-inTrain,]
```

##Modeling with Random Forest
First we set the train control to be 5-fold cross-validation and than we train the model with random forest method. 
```{r model}
train_control <- trainControl( method="cv", number=5)
fit <- train(classe ~ ., data=training, model="rf", trControl=train_control)
prediction <- predict(fit, newdata=testing)
acc<-sum(prediction == testing$classe) / length(prediction)
```
Now we can check the prediction against the data. The  accuracy is `r acc`. Which is quite high, there is no need to try a different model.
Let us see what are the most imporant variables.

```{r importance}
varImp(fit)
```
Now we predict on the real test data.
```{r prediction}
predTest<-predict(fit, newData=test)

```
##Conclusion

A model was made with 5-fold cross validation and random forest, which led to 99% accuracy. The most important predictors are roll_belt, yaw_belt     magnet_dumbbell_z, magnet_dumbbell_y, pitch_forearm, pitch_belt, magnet_dumbbell_x and roll_forearm.  